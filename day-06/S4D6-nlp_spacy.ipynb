{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'flying', 'to', 'Manila', '.']\n"
     ]
    }
   ],
   "source": [
    "### tokenization\n",
    "doc = nlp(u\"I am flying to Manila.\")\n",
    "print([word.text for word in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the\n",
      "quicker quick\n",
      "brown brown\n",
      "foxes fox\n",
      "jump jump\n",
      "over over\n",
      "the the\n",
      "lazier lazy\n",
      "dog dog\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "### lemmatization\n",
    "doc = nlp(u\"The quicker brown foxes jump over the lazier dog.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "have AUX\n",
      "flown VERB\n",
      "to ADP\n",
      "Cebu PROPN\n",
      ". PUNCT\n",
      "Now ADV\n",
      "I PRON\n",
      "am AUX\n",
      "flying VERB\n",
      "to ADP\n",
      "Manila PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "### POS tagging\n",
    "doc = nlp(u\"I have flown to Cebu. Now I am flying to Manila.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pronoun, personal'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PRP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, have, flown, to, Cebu, .]\n",
      "[Now, I, am, flying, to, Manila, .]\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([sent[i] for i in range(len(sent))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The, Golden, Gate, Bridge, is, an, iconic, landmark, in, San, Francisco, .]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u\"The Golden Gate Bridge is an iconic landmark in San Francisco.\")\n",
    "[doc[i] for i in range(len(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET\n",
      "Golden Gate Bridge Golden Gate Bridge PROPN\n",
      "is be AUX\n",
      "an an DET\n",
      "iconic iconic ADJ\n",
      "landmark landmark NOUN\n",
      "in in ADP\n",
      "San Francisco San Francisco PROPN\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[1:4])\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[7:9])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON nsubj nominal subject\n",
      "want VERB ROOT None\n",
      "a DET det determiner\n",
      "green ADJ amod adjectival modifier\n",
      "apple NOUN dobj direct object\n",
      ". PUNCT punct punctuation\n"
     ]
    }
   ],
   "source": [
    "### Syntactic Parsing\n",
    "doc = nlp(u\"I want a green apple.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"The firm earned $1.5 million in 2017.\")\n",
    "phrase = \"\"\n",
    "for token in doc:\n",
    "    if token.tag_ == \"$\":\n",
    "        i = token.i + 1\n",
    "        while doc[i].tag == \"CD\":\n",
    "            phrase += doc[i].text + \" \"\n",
    "            i += 1\n",
    "        break\n",
    "\n",
    "phrase = phrase[:-1]\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1.5 million\n",
      "$1.2 million\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(u\"The firm earned $1.5 million in 2017, in comparison with $1.2 million in 2016.\")\n",
    "phrase = \"\"\n",
    "for token in doc:\n",
    "    if token.tag_ == \"$\":\n",
    "        phrase = token.text\n",
    "        i = token.i + 1\n",
    "        while doc[i].tag_ == \"CD\":\n",
    "            phrase += doc[i].text + \" \"\n",
    "            i += 1\n",
    "        phrase = phrase[:-1]\n",
    "        print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$1.5 million', '$1.2 million']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "pattern = \"\\$.+?million\"\n",
    "test_string = \"The firm earned $1.5 million in 2017, in comparison with $1.2 million in 2016.\"\n",
    "result = re.findall(pattern, test_string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776482403927138"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### similarity\n",
    "doc = nlp(u\"I want a green apple.\")\n",
    "doc.similarity(doc[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.similarity(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5831844168885263"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"apple\").similarity(nlp(\"banana\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252610345406867"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"king\").similarity(nlp(\"queen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
